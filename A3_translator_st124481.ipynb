{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#import important library\n",
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.2+cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "I would like to give credit for data source I use.\n",
    "https://airesearch.in.th/releases/machine-translation-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'en'\n",
    "TRG_LANGUAGE = 'th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'task_master_1.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm in Los Angeles\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[245][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is your location?', 'คุณอยูาแถวไหนคะ?')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert data to tuple\n",
    "tuple_data = tuple(df.to_records(index=False))\n",
    "tuple_data[244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tuple data into list\n",
    "data = list(tuple_data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222733"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) #there are 222733 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split data into train, val, and test \n",
    "\n",
    "# Define the proportions for train, test, and validation sets\n",
    "train_size = 0.8  # 80% for training\n",
    "test_size = 0.1  # 10% for testing\n",
    "val_size = 0.1   # 10% for validation\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "train_data, temp_data = train_test_split(data, test_size=(test_size + val_size), random_state=42)\n",
    "test_data, val_data = train_test_split(temp_data, test_size=val_size/(test_size + val_size), random_state=42)\n",
    "train_data = list(train_data)\n",
    "val_data = list(val_data)\n",
    "test_data = list(test_data)\n",
    "\n",
    "# Print the lengths of the resulting sets\n",
    "# print(\"Train set length:\", len(train_data))\n",
    "# print(\"Test set length:\", len(test_data))\n",
    "# print(\"Validation set length:\", len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I use nltk for tokenize English sentences, and pythainlp to tokenize Thai sentences\n",
    "from nltk.tokenize import word_tokenize as nltk_word_tokenize\n",
    "from pythainlp.tokenize import word_tokenize as pythainlp_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_transform function\n",
    "token_transform[SRC_LANGUAGE] = lambda x: list(nltk_word_tokenize(x))\n",
    "token_transform[TRG_LANGUAGE] = lambda x: list(pythainlp_word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Sure, do you want it shipped to your location?\n",
      "Tokenization:  ['Are', 'you', 'looking', 'for', 'the', 'Driver', \"'s\", 'ETA', 'or', 'the', 'trip', 'duration', '?']\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", train_data[0][0])\n",
    "# print(\"Tokenization: \", token_transform['en'](train_data[0]))\n",
    "print(\"Tokenization: \", token_transform['en'](train_data[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {'en': 0, 'th': 1}\n",
    "\n",
    "    # for data_sample in data:\n",
    "    #     # yield token_transform[language][language_index[language]]\n",
    "    #     yield token_transform[language](data_sample[language_index[language]])\n",
    "    for i, data_sample in enumerate(data):\n",
    "        try:\n",
    "            yield token_transform[language](data_sample[language_index[language]])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Numericalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "#     print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_data, ln), \n",
    "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val_data,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, th in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "# print(\"Thai shape: \", th.shape)   # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device,att):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device, att)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        _src    = self.feedforward(src)\n",
    "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device,att, max_length = 700):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device,att)\n",
    "                                           for _ in range(n_layers)])\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len    = src.shape[1]\n",
    "        \n",
    "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, src_len]\n",
    "        \n",
    "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device, att):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim  = hid_dim\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "\n",
    "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        self.att      = att\n",
    "                \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        #src, src, src, src_mask\n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        #Q=K=V: [batch_size, src len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q = [batch_size, n heads, query len, head_dim]\n",
    "        \n",
    "        if self.att == 'general':\n",
    "            energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        #energy = [batch_size, n heads, query len, key len]\n",
    "        elif self.att == 'multi':\n",
    "            energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        elif self.att == 'addictive':\n",
    "            energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        #attention = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        #x = [batch_size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
    "        #x = [batch_size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device, att):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device, att)\n",
    "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device, att)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        #attention = [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        _trg = self.feedforward(trg)\n",
    "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, device,att,max_length = 700):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device,att)\n",
    "                                            for _ in range(n_layers)])\n",
    "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len    = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        #attention: [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch_size, trg len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(16282, 256)\n",
       "    (pos_embedding): Embedding(700, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(12154, 256)\n",
       "    (pos_embedding): Embedding(700, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=12154, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc1 = Encoder(input_dim, \n",
    "              hid_dim, \n",
    "              enc_layers, \n",
    "              enc_heads, \n",
    "              enc_pf_dim, \n",
    "              enc_dropout, \n",
    "              device, 'general')\n",
    "\n",
    "dec1 = Decoder(output_dim, \n",
    "              hid_dim, \n",
    "              dec_layers, \n",
    "              dec_heads, \n",
    "              dec_pf_dim, \n",
    "              enc_dropout, \n",
    "              device, 'general')\n",
    "enc2 = Encoder(input_dim, \n",
    "              hid_dim, \n",
    "              enc_layers, \n",
    "              enc_heads, \n",
    "              enc_pf_dim, \n",
    "              enc_dropout, \n",
    "              device, 'multi')\n",
    "\n",
    "dec2 = Decoder(output_dim, \n",
    "              hid_dim, \n",
    "              dec_layers, \n",
    "              dec_heads, \n",
    "              dec_pf_dim, \n",
    "              enc_dropout, \n",
    "              device, 'multi')\n",
    "\n",
    "model1 = Seq2SeqTransformer(enc1, dec1, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model1.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "# count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0005\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model1.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_len, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg    = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg    = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_len, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 5\n",
    "clip       = 1\n",
    "\n",
    "save_path = f'models/{model1.__class__.__name__}.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model1, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model1, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model1.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddsth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.019 | Test PPL:   7.529 |\n"
     ]
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model1, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Hi, I'm looking to book a table for Korean fod.\", 'สวัสดีค่ะ ช่วยจองร้านอาหารเกาหลีให้หน่อยได้มั้ยคะ?')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ok, what area are you thinking about?', 'ได้เลยค่ะ แถวไหนดีคะ?')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  102,    5,    8,   60,  169,   10,   88,   11,  144,   12, 1379,\n",
       "           0,    4,    3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](data[0][0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,     0,   660,     4,     0,     4,     0,     4,     0,     4,\n",
       "        10000,     4,     0,     4,     0,    30,     3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](data[1][0]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15]), torch.Size([1, 17]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model1(src_text, trg_text) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 12154])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 12154])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12154])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   4,    4,  469,    4, 1475,    4,    5,    4,    5,    4,    5,    4,\n",
       "           5,    4,    3,    3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "ออ\n",
      " \n",
      "เกาหลี\n",
      " \n",
      "ค่ะ\n",
      " \n",
      "ค่ะ\n",
      " \n",
      "ค่ะ\n",
      " \n",
      "ค่ะ\n",
      " \n",
      "<eos>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 17, 15])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 15])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Hi',\n",
       " ',',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'looking',\n",
       " 'to',\n",
       " 'book',\n",
       " 'a',\n",
       " 'table',\n",
       " 'for',\n",
       " 'Korean',\n",
       " 'fod',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](data[0][0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " ' ',\n",
       " ' ',\n",
       " 'ออ',\n",
       " ' ',\n",
       " 'เกาหลี',\n",
       " ' ',\n",
       " 'ค่ะ',\n",
       " ' ',\n",
       " 'ค่ะ',\n",
       " ' ',\n",
       " 'ค่ะ',\n",
       " ' ',\n",
       " 'ค่ะ',\n",
       " ' ',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thama\\AppData\\Local\\Temp\\ipykernel_35156\\59549304.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "C:\\Users\\thama\\AppData\\Local\\Temp\\ipykernel_35156\\59549304.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(y_ticks)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3629 (\\N{THAI CHARACTER O ANG}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3648 (\\N{THAI CHARACTER SARA E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3585 (\\N{THAI CHARACTER KO KAI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3634 (\\N{THAI CHARACTER SARA AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3627 (\\N{THAI CHARACTER HO HIP}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3621 (\\N{THAI CHARACTER LO LING}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3637 (\\N{THAI CHARACTER SARA II}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3588 (\\N{THAI CHARACTER KHO KHWAI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3656 (\\N{THAI CHARACTER MAI EK}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\thama\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 3632 (\\N{THAI CHARACTER SARA A}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
